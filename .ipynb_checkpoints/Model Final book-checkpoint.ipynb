{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting plots.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile plots.py\n",
    "\n",
    "#Author: Pelani Malange\n",
    "'''\n",
    "This procedure used pipe model, will need to modify for model.fit \n",
    "\n",
    "adopted from Author: Taylor Smith <taylor.smith@alkaline-ml.com>\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import uuid\n",
    "from datetime import date\n",
    "import time\n",
    "from collections import Counter,defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import socket\n",
    "import capstone_eda as cp\n",
    "import pmdarima as pm\n",
    "from pmdarima import pipeline\n",
    "from pmdarima import model_selection\n",
    "from pmdarima import preprocessing as ppc\n",
    "from pmdarima import arima\n",
    "from pmdarima import auto_arima \n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX \n",
    "from matplotlib import pyplot as plt\n",
    "from flask import Flask\n",
    "\n",
    "def create_predplots(ts,test,pipe,train):\n",
    "        # Let's take a look at the actual vs. the predicted values:\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Visualize goodness of fit\n",
    "        print(\"Visualise goodness of fit\")\n",
    "        in_sample_preds, in_sample_confint = \\\n",
    "        pipe.predict_in_sample(X=None, return_conf_int=True)\n",
    "\n",
    "        n_train = train.shape[0]\n",
    "\n",
    "        x0 = np.arange(n_train)\n",
    "        axes[0].plot(x0, train, alpha=0.75)\n",
    "        axes[0].scatter(x0, in_sample_preds, alpha=0.4, marker='x',color='g')\n",
    "        axes[0].fill_between(x0, in_sample_confint[:, 0], in_sample_confint[:, 1],\n",
    "                     alpha=0.1, color='b')\n",
    "        axes[0].set_title('Actual train samples vs. in-sample predictions')\n",
    "        axes[0].set_xlim((0, x0.shape[0]))\n",
    "\n",
    "        # Visualize actual + predicted\n",
    "        x1 = np.arange(n_train + preds.shape[0])\n",
    "        axes[1].plot(x1[:n_train], train, alpha=0.75)\n",
    "        # axes[1].scatter(x[n_train:], preds, alpha=0.4, marker='o')\n",
    "        axes[1].scatter(x1[n_train:], test[:preds.shape[0]], alpha=0.4, marker='x')\n",
    "        axes[1].fill_between(x1[n_train:], conf_int[:, 0], conf_int[:, 1],\n",
    "                     alpha=0.1, color='b')\n",
    "        axes[1].set_title('Actual test samples vs. forecasts')\n",
    "        axes[1].set_xlim((0, ts.shape[0]))\n",
    "\n",
    "        # We can also call `update` directly on the pipeline object, which will update\n",
    "        # the intermittent transformers, where necessary:\n",
    "        newly_observed, still_test = test[:15], test[15:]\n",
    "        pipe.update(newly_observed, maxiter=10)\n",
    "\n",
    "        # Calling predict will now predict from newly observed values\n",
    "        new_preds = pipe.predict(still_test.shape[0])\n",
    "        print(new_preds)\n",
    "\n",
    "        x2 = np.arange(ts.shape[0])\n",
    "        n_trained_on = n_train + newly_observed.shape[0]\n",
    "\n",
    "        axes[2].plot(x2[:n_train], train, alpha=0.75)\n",
    "        axes[2].plot(x2[n_train: n_trained_on], newly_observed, alpha=0.75, c='orange')\n",
    "        # axes[2].scatter(x2[n_trained_on:], new_preds, alpha=0.4, marker='o')\n",
    "        axes[2].scatter(x2[n_trained_on:], still_test, alpha=0.4, marker='x')\n",
    "        axes[2].set_title('Actual test samples vs. forecasts')\n",
    "        axes[2].set_xlim((0, ts.shape[0]))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #include data ingestion module \n",
    "    \n",
    "    \n",
    "    #fetch data and engineer feature for revenue analysis \n",
    "    df =fetch_data()\n",
    "    #convert to time series data \n",
    "    df[\"invoice_date\"] = pd.to_datetime(df['invoice_date'], format='%d.%m.%Y')## create time series\n",
    "    ts = df.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    ts.head()\n",
    "    #ts.tail()\n",
    "    ts.plot()\n",
    "    print(\"Split data for training \")\n",
    "    train, test = split_train_test(ts, test=\"2019-04-01\")\n",
    "    train, test = model_selection.train_test_split(data, test_size=0.2)\n",
    "    \n",
    "    #model file \n",
    "    saved_model = \"sales-arima-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "    #train model\n",
    "    pipe = model_train(ts,train,saved_model)\n",
    "    \n",
    "    \n",
    "    #predict values , default 3 months\n",
    "    preds ,conf_int = model_predict(pipe,num_months, saved_model, return_conf_int=True)\n",
    "    #print(preds)\n",
    "    \n",
    "    #plot diagrams of the model perfomance\n",
    "    \n",
    "    \n",
    "    create_predplots(ts,test,pipe,train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model training module\n",
    "The model will be trained on daily revenue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modelapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modelapp.py\n",
    "\n",
    "print(__doc__)\n",
    "#Author : Pelani Malange <pmalange@za.ibm.com>\n",
    "\n",
    "# this is a standalone model app , for the sake of the project , the module is part of pred app\n",
    "import numpy as np \n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import socket\n",
    "from logger import  update_predict_log, update_train_log\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd  \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose \n",
    "from flask import Flask\n",
    "from matplotlib import pyplot as plt\n",
    "from pmdarima import auto_arima\n",
    "import pmdarima as pm\n",
    "from pmdarima import model_selection\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX \n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from flask import Flask, jsonify, request, Response\n",
    "from flask_json import FlaskJSON, JsonError,json_response,as_json\n",
    "\n",
    "MODEL_VERSION = \"0.1\"\n",
    "MODEL_VERSION_NOTE = \"auto_arima\"\n",
    "\n",
    "## specify the directory you saved the data and images in\n",
    "DATA_DIR = os.path.join(\".\",\"data\")\n",
    "IMAGE_DIR = os.path.join(\".\",\"images\")\n",
    "MODEL_DIR  = os.path.join(\".\",\"models\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "json = FlaskJSON(app)\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def statusping():\n",
    "    html = \"<h3>Model says hello  {name}!</h3>\" \\\n",
    "           \"<b>Hostname:</b> {hostname}<br/>\"\n",
    "    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname())\n",
    "\n",
    "def fetch_data(country ):\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, \"top10countries-data.csv\"),index_col=\"invoice_date\", parse_dates=True)\n",
    "    #print(\"df: {} x {}\".format(df.shape[0], df.shape[1]))\n",
    "\n",
    "    ## check the first few rows\n",
    "    #print(\"\\n  Check first 4 rows\\n\")\n",
    "    #print(df.head(n=4))\n",
    "   \n",
    "    df = df[df['country']==country]\n",
    "    ts = df.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    y_ts = ts.resample('MS').mean()\n",
    "    \n",
    "    \n",
    "    return y_ts\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "@app.route('/train')\n",
    "def model_train ():\n",
    "    \n",
    "    #get country \n",
    "    data = request.get_json(force=True)\n",
    "    ## input checking\n",
    "\n",
    "    #get the number of months to forecast\n",
    "     #select the country model\n",
    "        \n",
    "    try:#value = int(data['value'])\n",
    "        country  = data['country']\n",
    "    except (KeyError,TypeError,ValueError):\n",
    "        raise JsonError(description='Invalid value')\n",
    "\n",
    "    #format the country variable\n",
    "    if country.isspace():\n",
    "        str_country= country\n",
    "        str_country = re.sub(r\"\\s+\",'-',str_country)\n",
    "        str_country =str_country.lower()\n",
    "    else:\n",
    "        str_country = country.lower()\n",
    "        \n",
    "    #set country model\n",
    "    saved_model = str_country+\"-\"+\"sales-arima-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "    #filter data to train based on country \n",
    "    y =fetch_data(country)\n",
    "    \n",
    "    # Split data into train / test sets \n",
    "    train, test = model_selection.train_test_split(y, test_size=0.1)\n",
    "    \n",
    "    #model = auto_arima(train, trace=True,error_action='ignore',suppress_warnings=True)\n",
    "    \n",
    "    \n",
    "    # Seasonal - fit stepwise auto-ARIMA\n",
    "    #with ARIMA, due to size of the data , weshall not use train split\n",
    "    model = pm.auto_arima(y, start_p=1, start_q=1,\n",
    "                         test='adf',\n",
    "                         max_p=3, max_q=3, m=12,\n",
    "                         start_P=0, seasonal=True,\n",
    "                         d=None, D=1, trace=True,\n",
    "                         error_action='ignore',  \n",
    "                         suppress_warnings=True, \n",
    "                         stepwise=True)\n",
    "\n",
    "    #smodel.summary()\n",
    "    result = model.fit(train)\n",
    "    \n",
    "    \n",
    "    #print Autom arima diagnostics\n",
    "    #results.plot_diagnostics(figsize=(16, 8))\n",
    "    #plt.show()\n",
    "   \n",
    "    \n",
    "    joblib.dump(model, os.path.join(MODEL_DIR, saved_model))\n",
    "    #result.plot_diagnostics(figsize=(15,12))\n",
    "   \n",
    "    \n",
    "    #print( result.summary().tables[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(\"\\n Proceed with Auto Arima due to better AIC value\\n\")\n",
    "    #forecast \n",
    "    \n",
    "    \n",
    "    forecast  =  model.predict(n_periods=len(test))\n",
    "    forecast  = pd.DataFrame(forecast,index=test.index,columns=['predictions'])\n",
    "   \n",
    "    #hide the plots as this will be caled via scripts\n",
    "    #plot\n",
    "    '''\n",
    "    plt.plot(train,label='Train')\n",
    "    plt.plot(test, label='Valid')\n",
    "    plt.plot(forecast, label ='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    '''\n",
    "   \n",
    "    rms = round(sqrt(mean_squared_error(test,forecast)),2)\n",
    "    #print(\"Arima rms \\n:{}\",model_train ())\n",
    "    \n",
    "    mape_result = round(mean_absolute_percentage_error(test,forecast))\n",
    "    \n",
    "    return json_response(rmse = rms, mape=mape_result)\n",
    "   \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    app.run(debug=True, host='0.0.0.0', port=8080)\n",
    "    #app.run(host='0.0.0.0', port=8080,debug=True)\n",
    "    \n",
    "    # ETS Decomposition \n",
    "    #df = fetch_data()\n",
    "    #convert to time series data \n",
    "    #df[\"invoice_date\"] = pd.to_datetime(df['invoice_date'], format='%d.%m.%Y')## create time series\n",
    "    #ts = df.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    #y_ts = ts.resample('MS').mean()\n",
    "    #print(\"y[2019] is \\n{}\",y_ts[\"2019\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Converting the index as date\n",
    "    #print(ts.describe())\n",
    "    #ts.tail()\n",
    "    #print(\"Show y averages per month\\n{}\")\n",
    "    #y.plot(figsize=(15, 6))\n",
    "    #plt.show()\n",
    "    \n",
    "    #print(\"Show TS averaged monthly normal{}\")\n",
    "    #y_ts.plot()\n",
    "    #plt.show()\n",
    "    #result = seasonal_decompose(y_ts, period=1) \n",
    "    \n",
    "    #print(\"Show seasonal decomposition across 1 month average  due to TS monthly average\")\n",
    "    #rcParams['figure.figsize'] = 18, 8\n",
    "    #decomposition = seasonal_decompose(y_ts, model='additive',period=1)\n",
    "    #fig = decomposition.plot()\n",
    "    #plt.show()\n",
    "    \n",
    "    #data range\n",
    "    #print ( \"\\n Data range  start : {} and end: {}\",ts['invoice_date'].min(), ts['invoice_date'].max())\n",
    "  \n",
    "    # ETS plot  \n",
    "    #result.plot() \n",
    "   # pre_train(train)\n",
    "    \n",
    "    #model file \n",
    "    #saved_model = \"sales-arima-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "    #results = model_train(train,test,saved_model)\n",
    "    #validate(results,y_ts)\n",
    "   \n",
    "    \n",
    "    \n",
    "    #rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      " * Serving Flask app \"modelapp\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      "None\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 913-535-581\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,2,1)(0,1,1)[12]             : AIC=inf, Time=0.39 sec\n",
      " ARIMA(0,2,0)(0,1,0)[12]             : AIC=124.585, Time=0.03 sec\n",
      " ARIMA(1,2,0)(1,1,0)[12]             : AIC=inf, Time=0.21 sec\n",
      " ARIMA(0,2,1)(0,1,1)[12]             : AIC=inf, Time=0.16 sec\n",
      " ARIMA(0,2,0)(1,1,0)[12]             : AIC=inf, Time=0.11 sec\n",
      " ARIMA(0,2,0)(0,1,1)[12]             : AIC=inf, Time=0.10 sec\n",
      " ARIMA(0,2,0)(1,1,1)[12]             : AIC=122.640, Time=0.17 sec\n",
      " ARIMA(0,2,0)(2,1,1)[12]             : AIC=inf, Time=0.23 sec\n",
      " ARIMA(0,2,0)(1,1,2)[12]             : AIC=inf, Time=0.72 sec\n",
      " ARIMA(0,2,0)(0,1,2)[12]             : AIC=inf, Time=0.56 sec\n",
      " ARIMA(0,2,0)(2,1,0)[12]             : AIC=inf, Time=0.37 sec\n",
      " ARIMA(0,2,0)(2,1,2)[12]             : AIC=inf, Time=3.36 sec\n",
      " ARIMA(1,2,0)(1,1,1)[12]             : AIC=inf, Time=0.48 sec\n",
      " ARIMA(0,2,1)(1,1,1)[12]             : AIC=inf, Time=0.42 sec\n",
      " ARIMA(1,2,1)(1,1,1)[12]             : AIC=inf, Time=0.62 sec\n",
      " ARIMA(0,2,0)(1,1,1)[12] intercept   : AIC=inf, Time=0.41 sec\n",
      "\n",
      "Best model:  ARIMA(0,2,0)(1,1,1)[12]          \n",
      "Total fit time: 8.383 seconds\n",
      "127.0.0.1 - - [01/Feb/2021 10:45:27] \"\u001b[37mGET /train HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 modelapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per comparison, using  averaged  time series value  for Autoarima model gives better perfomance,\n",
    "although an argument can be on the model fit, which can seen proved in the following chart below \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and  Prediction \n",
    "In this section we show the prediction module\n",
    "\n",
    "Automatically discover the optimal order for an ARIMA model.\n",
    "\n",
    "The auto-ARIMA process seeks to identify the most optimal parameters for an ARIMA model, settling on a single fitted ARIMA model. This process is based on the commonly-used R function, forecast::auto.arima\n",
    "\n",
    "Auto-ARIMA works by conducting differencing tests (i.e., Kwiatkowski–Phillips–Schmidt–Shin, Augmented Dickey-Fuller or Phillips–Perron) to determine the order of differencing, d, and then fitting models within ranges of defined start_p, max_p, start_q, max_q ranges. If the seasonal optional is enabled, auto-ARIMA also seeks to identify the optimal P and Q hyper- parameters after conducting the Canova-Hansen to determine the optimal order of seasonal differencing, D.\n",
    "\n",
    "In order to find the best model, auto-ARIMA optimizes for a given information_criterion, one of (‘aic’, ‘aicc’, ‘bic’, ‘hqic’, ‘oob’) (Akaike Information Criterion, Corrected Akaike Information Criterion, Bayesian Information Criterion, Hannan-Quinn Information Criterion, or “out of bag”–for validation scoring–respectively) and returns the ARIMA which minimizes the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/predapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/predapp.py\n",
    "print(__doc__)\n",
    "\n",
    "# Author: Pelani Malange <pmalange@za.ibm.com>\n",
    "# App will service model train and prediction\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import uuid\n",
    "from datetime import date, datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from collections import Counter,defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "import socket\n",
    "from werkzeug.utils import secure_filename\n",
    "import pmdarima as pm\n",
    "from pmdarima import pipeline\n",
    "from pmdarima import model_selection\n",
    "from pmdarima import preprocessing as ppc\n",
    "from pmdarima import arima\n",
    "from flask import Flask, jsonify, request,redirect\n",
    "from flask_json import FlaskJSON, JsonError,json_response,as_json\n",
    "from logger import update_train_log, update_predict_log\n",
    "\n",
    "MODEL_VERSION = \"0.1\"\n",
    "MODEL_VERSION_NOTE = \"auto_arima\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(\".\",\"data\")):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "## specify the directory you saved the data and images in\n",
    "DATA_DIR = os.path.join(\".\",\"data\")\n",
    "IMAGE_DIR = os.path.join(\".\",\"images\")\n",
    "MODEL_DIR  = os.path.join(\".\",\"models\")\n",
    "PRED_DIR = os.path.join(\".\",\"preds\")\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "json_flask = FlaskJSON(app)\n",
    "\n",
    "#@app.route(\"/\")\n",
    "def statusping():\n",
    "    html = \"<h3>Flask predict says Hello {name}!</h3>\" \\\n",
    "           \"<b>Hostname:</b> {hostname}<br/>\"\n",
    "    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname())\n",
    "\n",
    "\n",
    "def update_target(target_file,df, overwrite=False):\n",
    "    \"\"\"\n",
    "    update line by line in case data are large\n",
    "    \"\"\"\n",
    "\n",
    "    if overwrite or not os.path.exists(target_file):\n",
    "        df.to_csv(target_file, index=True)   \n",
    "    else:\n",
    "        df.to_csv(target_file, mode='a', header=False, index=True)\n",
    "\n",
    "        \n",
    "@app.route('/home',methods=['POST','GET'])\n",
    "def showId():\n",
    "    data = request.get_json(force=True)\n",
    "    try :\n",
    "        value = int(data['value'])\n",
    "    except (KeyError,TypeError,ValueError):\n",
    "        raise JsonError(description='Invalid value')\n",
    "    return json_response(value=value + 1)\n",
    "\n",
    "@app.route('/get_value')\n",
    "@as_json\n",
    "def get_value():\n",
    "    return dict(value=12)\n",
    "    \n",
    "\n",
    "#train model section\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def fetch_data(country,df ):\n",
    "    #df = pd.read_csv(os.path.join(DATA_DIR, \"top10countries-data.csv\"),index_col=\"invoice_date\", parse_dates=True)\n",
    "    #print(\"df: {} x {}\".format(df.shape[0], df.shape[1]))\n",
    "\n",
    "    ## check the first few rows\n",
    "    #print(\"\\n  Check first 4 rows\\n\")\n",
    "    #print(df.head(n=4))\n",
    "   \n",
    "    df = df[df.index==country]\n",
    "    ts = df.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    y_ts = ts.resample('MS').mean()\n",
    "    \n",
    "    \n",
    "    return y_ts\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def fetch_data(query):\n",
    "    #df = pd.read_csv(os.path.join(DATA_DIR, \"top10countries-data.csv\"),index_col=0, parse_dates=['invoice_date'])\n",
    "    f = open (os.path.join(DATA_DIR,query),\"r\")\n",
    "    dt = json.loads(f.read())\n",
    "    df = pd.read_json(dt,orient='split',convert_dates=[\"invoice_date\"])\n",
    "    #df = pd.read_json(os.path.join(DATA_DIR,\"data.txt\"))\n",
    "    print(\"df size : {} x {}\".format(df.shape[0], df.shape[1]))\n",
    "    df = df.round(2)\n",
    "    ## check the first few rows\n",
    "    print(\"\\n  Check first 4 rows\\n\")\n",
    "    print(df.head(n=4))\n",
    "    \n",
    "    return df \n",
    "def filter_cntry_data(df,country):\n",
    "    #if !df.country.index:\n",
    "    #    df = df.set_index('country')\n",
    "    \n",
    "    df = df[df.index==country]\n",
    "    ts = df.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    y_ts = ts.resample('MS').mean()\n",
    "    \n",
    "    return y_ts\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "@app.route('/uploadfile',methods=['POST'])\n",
    "def uploadfile():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        if f.filename !='':\n",
    "            f.save(os.path.join(DATA_DIR,f.filename))\n",
    "        filenm=f.filename\n",
    "    return filenm\n",
    "\n",
    "@app.route('/train',methods=['POST'])\n",
    "def model_train ():\n",
    "    \n",
    "    filenm=\"\"\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        if f.filename !='':\n",
    "            f.save(os.path.join(DATA_DIR,f.filename))\n",
    "        filenm=f.filename\n",
    "\n",
    "    data = fetch_data(filenm)\n",
    "    \n",
    "    #get country  old code\n",
    "    #data = request.get_json(force=True)\n",
    "    #data = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    #create dataframe for temporary capture of traiing results \n",
    "    df_res = pd.DataFrame(columns=[\"country\",\"rmse\",\"mape\"])\n",
    "    \n",
    "    ## input checking\n",
    "\n",
    "    #get the number of months to forecast\n",
    "     #select the country model\n",
    "        \n",
    "    try:#value = int(data['value'])\n",
    "        country = data.index.unique().tolist()\n",
    "    except (KeyError,TypeError,ValueError):\n",
    "        raise JsonError(description='Invalid value')\n",
    "            \n",
    "    #enforce datetime astype on cloumn invoice_date\n",
    "    #data[\"invoice_date\"] = pd.to_datetime(data[\"invoice_date\"])\n",
    "\n",
    "     ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "    \n",
    "    c_listlen= len(country)\n",
    "    \n",
    "    \n",
    "    ts = data.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    y_all = ts.resample('MS').mean()\n",
    "    \n",
    "    # Seasonal - fit stepwise auto-ARIMA\n",
    "        #with ARIMA, due to size of the data , weshall not use train split\n",
    "    #Having checked the ARIMA fit model, all countries repor the same hyperparameters\n",
    "    #Training will be done however per country\n",
    "    model = pm.auto_arima(y_all, start_p=1, start_q=1,\n",
    "                             max_p=3, max_q=3, m=12,\n",
    "                             start_P=0, seasonal=True,\n",
    "                             d=None, D=1, trace=True,\n",
    "                             error_action='ignore',  \n",
    "                             suppress_warnings=True, \n",
    "                             stepwise=True)\n",
    "    \n",
    "    for i in range(c_listlen):\n",
    "        cntry = country[i]\n",
    "        #format the country variable\n",
    "        if cntry.isspace():\n",
    "            str_country= cntry\n",
    "            str_country = re.sub(r\"\\s+\",'-',str_country)\n",
    "            str_country =str_country.lower()\n",
    "        else:\n",
    "            str_country = cntry.lower()\n",
    "\n",
    "        #set country model\n",
    "        saved_model = str_country+\"-\"+\"sales-arima-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "        #filter data to train based on country \n",
    "        y =filter_cntry_data(data,cntry)\n",
    "\n",
    "        # Split data into train / test sets \n",
    "        train, test = model_selection.train_test_split(y, test_size=0.1)\n",
    "\n",
    "        \n",
    "\n",
    "        #smodel.summary()\n",
    "        result = model.fit(train)\n",
    "      \n",
    "\n",
    "\n",
    "        #print Autom arima diagnostics\n",
    "        #results.plot_diagnostics(figsize=(16, 8))\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "        joblib.dump(model, os.path.join(MODEL_DIR, saved_model))\n",
    "        #result.plot_diagnostics(figsize=(15,12))\n",
    "\n",
    "\n",
    "        #print( result.summary().tables[1])\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"\\n Proceed with Auto Arima due to better AIC value\\n\")\n",
    "        #forecast \n",
    "\n",
    "\n",
    "        forecast  =  model.predict(n_periods=len(test))\n",
    "        forecast  = pd.DataFrame(forecast,index=test.index,columns=['predictions'])\n",
    "\n",
    "        #hide the plots as this will be caled via scripts\n",
    "        #plot\n",
    "        '''\n",
    "        plt.plot(train,label='Train')\n",
    "        plt.plot(test, label='Valid')\n",
    "        plt.plot(forecast, label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        rms = round(sqrt(mean_squared_error(test,forecast)),2)\n",
    "        #print(\"Arima rms \\n:{}\",model_train ())\n",
    "\n",
    "        mape_result = round(mean_absolute_percentage_error(test,forecast))\n",
    "\n",
    "        df_res.loc[i] = [cntry,rms, mape_result] \n",
    "        m, s = divmod(time.time()-time_start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "        update_train_log(y.shape[0],{'country':cntry,'rmse':rms,'mape':mape_result,'AIC':result.aic},runtime,MODEL_VERSION, MODEL_VERSION_NOTE, test=True)\n",
    "\n",
    "        \n",
    "       \n",
    "          ## train logger\n",
    "       \n",
    "        \n",
    "    #return json_response(rmse = rms, mape=mape_result)\n",
    "    return dict(df_res.to_dict())\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "# end of train model section\n",
    "\n",
    "def model_update():\n",
    "    # We can also call `update` directly on the pipeline object, which will update\n",
    "    # the intermittent transformers, where necessary:\n",
    "    data=fetch_data()\n",
    "    newly_observed, still_test = test[:15], test[15:]\n",
    "    model.update(newly_observed, maxiter=10)\n",
    "\n",
    "    # Calling predict will now predict from newly observed values\n",
    "    new_preds = model.predict(still_test.shape[0])\n",
    "    print(new_preds)\n",
    "    \n",
    "    \n",
    "    \n",
    "    filenm=\"\"\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        if f.filename !='':\n",
    "            f.save(os.path.join(DATA_DIR,f.filename))\n",
    "        filenm=f.filename\n",
    "\n",
    "    data = fetch_data(filenm)\n",
    "    \n",
    "\n",
    "    ## input checking\n",
    "\n",
    "    #get the number of months to forecast\n",
    "     #select the country model\n",
    "        \n",
    "    try:#value = int(data['value'])\n",
    "        country = data.index.unique().tolist()\n",
    "    except (KeyError,TypeError,ValueError):\n",
    "        raise JsonError(description='Invalid value')\n",
    "            \n",
    "     ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "    \n",
    "    c_listlen= len(country)\n",
    "    \n",
    "    \n",
    "    ts = data.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    y_all = ts.resample('MS').mean()\n",
    "    \n",
    "    for i in range(c_listlen):\n",
    "        cntry = country[i]\n",
    "        #format the country variable\n",
    "        if cntry.isspace():\n",
    "            str_country= cntry\n",
    "            str_country = re.sub(r\"\\s+\",'-',str_country)\n",
    "            str_country =str_country.lower()\n",
    "        else:\n",
    "            str_country = cntry.lower()\n",
    "\n",
    "        #set country model\n",
    "        saved_model = str_country+\"-\"+\"sales-arima-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "        #filter data to train based on country \n",
    "        y =filter_cntry_data(data,cntry)\n",
    "   \n",
    "        #smodel.summary()\n",
    "        result = model.update(y)\n",
    "      \n",
    "\n",
    "\n",
    "        #print Autom arima diagnostics\n",
    "        #results.plot_diagnostics(figsize=(16, 8))\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "        joblib.dump(model, os.path.join(MODEL_DIR, saved_model))\n",
    "        #result.plot_diagnostics(figsize=(15,12))\n",
    "\n",
    "\n",
    "        #print( result.summary().tables[1])\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"\\n Proceed with Auto Arima due to better AIC value\\n\")\n",
    "        #forecast \n",
    "\n",
    "\n",
    "        forecast  =  model.predict(n_periods=len(test))\n",
    "        forecast  = pd.DataFrame(forecast,index=test.index,columns=['predictions'])\n",
    "\n",
    "        #hide the plots as this will be caled via scripts\n",
    "        #plot\n",
    "        '''\n",
    "        plt.plot(train,label='Train')\n",
    "        plt.plot(test, label='Valid')\n",
    "        plt.plot(forecast, label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        rms = round(sqrt(mean_squared_error(test,forecast)),2)\n",
    "        #print(\"Arima rms \\n:{}\",model_train ())\n",
    "\n",
    "        mape_result = round(mean_absolute_percentage_error(test,forecast))\n",
    "\n",
    "        df_res.loc[i] = [cntry,rms, mape_result] \n",
    "        m, s = divmod(time.time()-time_start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "        update_train_log(y.shape[0],{'country':cntry,'rmse':rms,'mape':mape_result,'AIC':result.aic},runtime,MODEL_VERSION, MODEL_VERSION_NOTE, test=True)\n",
    "\n",
    "        \n",
    "       \n",
    "          ## train logger\n",
    "       \n",
    "        \n",
    "    #return json_response(rmse = rms, mape=mape_result)\n",
    "    return dict(df_res.to_dict())\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "@app.route('/predict',methods=['POST','GET'])\n",
    "def model_predict():\n",
    "    \n",
    "    num_periods = 30\n",
    "    ## input checking\n",
    "\n",
    "    data = request.get_json(force=True)\n",
    "    #get the number of months to forecast\n",
    "     #select the country model\n",
    "        \n",
    "    try:#value = int(data['value'])\n",
    "        country  = data['country']\n",
    "        idx_start_date = data['date']\n",
    "    except (KeyError,TypeError,ValueError):\n",
    "        raise JsonError(description='Invalid value')\n",
    "    idx_start_date = datetime.strptime(idx_start_date, '%d/%m/%Y')\n",
    "    end_period = idx_start_date + timedelta(num_periods)\n",
    "    \n",
    "    #select model based on country \n",
    "    str_country  = country.lower()\n",
    "    \n",
    "    \n",
    "    saved_model = str_country+\"-\"+\"sales-arima-0_1.joblib\"\n",
    "    model = joblib.load(os.path.join(MODEL_DIR, saved_model))\n",
    "    # We can compute predictions the same way we would on a normal ARIMA object:\n",
    "    ## input checking\n",
    "                          \n",
    "    print(\"... predicting\")\n",
    "    \n",
    "    \n",
    "    ## start timer for runtime\n",
    "    time_start = time.time()\n",
    "\n",
    "    \n",
    "    #preds, conf_int = pipe.predict(n_periods=periods, return_conf_int=True)\n",
    "    preds, conf_int = model.predict(start=idx_start_date,end=end_period, return_conf_int=True)\n",
    "    #index_of_fc = pd.date_range(ts.index[-1], periods = n_periods, freq='MS')\n",
    "    index_of_fc = pd.date_range(idx_start_date, periods = len(preds), freq='D')\n",
    "    # make series for plotting purpose\n",
    "    fitted_series = pd.Series(preds, index=index_of_fc)\n",
    "    df_series = fitted_series.to_frame()\n",
    "    df_series.columns = [\"proj_sales\"]\n",
    "    avgrevpred = df_series.proj_sales.mean().round(3)\n",
    "    \n",
    "    #print predicted values \n",
    "    \n",
    "     ## make prediction and gather data for log entry\n",
    "    y_proba = None\n",
    "    if 'predict_proba' in dir(model) and model.probability == True:\n",
    "        y_proba = model.predict_proba(n_periods=1)\n",
    "    \n",
    "    m, s = divmod(time.time()-time_start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    runtime = \"%03d:%02d:%02d\"%(h, m, s)\n",
    "    ## update the log file\n",
    "    #_update_predict_log(preds, y_proba,country, runtime)\n",
    "    \n",
    "    #update_predict_log(\"[0]\", \"[0.6,0.4]\",\"['united_states', 24, 'aavail_basic', 8]\",\"00:00:01\", MODEL_VERSION, test=True)\n",
    "    update_predict_log(preds, y_proba,data, runtime, MODEL_VERSION, test=False)\n",
    "    \n",
    "    #print results to outfile\n",
    "    update_target(os.path.join(PRED_DIR,str_country+'-preds.csv'),df_series,overwrite=True)\n",
    "    #_update_target(df_series)\n",
    "    \n",
    "    \n",
    "\n",
    "    #return jsonify(preds,conf_int)\n",
    "    #return jsonify(preds.tolist())\n",
    "\n",
    "    #return jsonify(avgrevpred)\n",
    "    return json_response(Predrevenue=avgrevpred)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    app.run(debug=True, host='0.0.0.0', port=8082)\n",
    "    #app.run(host='0.0.0.0', port=8080,debug=True)\n",
    "    \n",
    "    # select the model based on country \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      " * Serving Flask app \"predapp\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      "Traceback (most recent call last):\n",
      "  File \"./runtime/predapp.py\", line 353, in <module>\n",
      "    app.run(debug=True, host='0.0.0.0', port=8082)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/flask/app.py\", line 990, in run\n",
      "    run_simple(host, port, self, **options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/werkzeug/serving.py\", line 1030, in run_simple\n",
      "    s.bind(server_address)\n",
      "OSError: [Errno 48] Address already in use\n"
     ]
    }
   ],
   "source": [
    "!python3  ./runtime/predapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a deployment scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/Dockerfile\n",
    "\n",
    "# Use an official Python runtime as a parent image\n",
    "FROM python:3.7.5-stretch\n",
    "\n",
    "MAINTAINER Pelani Malange \"pmalange@za.ibm.com\"\n",
    "\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "python3-dev \\\n",
    "build-essential    \n",
    "        \n",
    "# Set the working directory to /app\n",
    "WORKDIR /app\n",
    "\n",
    "http://localhost:8888/notebooks/prj_capstone/Model%20Final%20book.ipynb## Copy the current directory contents into the container at /app\n",
    "ADD . /app\n",
    "\n",
    "# Install any needed packages specified in requirements.txt\n",
    "RUN pip3 install --upgrade pip\n",
    "RUN pip3 install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Make port 80 available to the world outside this container\n",
    "EXPOSE 80\n",
    "\n",
    "# Define environment variable\n",
    "ENV NAME World\n",
    "\n",
    "# Run app.py when the container launches\n",
    "CMD [\"python3\", \"predapp.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/requirements.txt\n",
    "#create a requirements file for docker\n",
    "\n",
    "cython\n",
    "numpy\n",
    "flask\n",
    "flask_json\n",
    "pandas\n",
    "pmdarima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test deployed modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction from specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Predrevenue': 23607.119, 'status': 200}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "'''\n",
    "Part A: forecast using existing models\n",
    "The script is expected to forecast for average revenue given a specific start date.\n",
    "test value = 01/08/2019\n",
    "country = United Kingdom\n",
    "'''\n",
    "\n",
    "## data needs to be in dict format for JSON\n",
    "query = dict({'date' :'01/08/2019','country':'united kingdom'})\n",
    "\n",
    "## test the Flask API\n",
    "# port = 8080\n",
    "# r = requests.post('http://0.0.0.0:{}/predict'.format(port),json=query)\n",
    "\n",
    "## test the Docker API\n",
    "port = 8082\n",
    "#r = requests.post('http://0.0.0.0:{}/predict/'.format(port),json=query)\n",
    "r = requests.get('http://0.0.0.0:{}/predict'.format(port),json=query)\n",
    "\n",
    "response = literal_eval(r.text)\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training with new data \n",
    "\n",
    "In this section , we shall simulate training the forecast with new data.\n",
    "\n",
    "Prerequisites. \n",
    "\n",
    "1.  Files will be in json format \n",
    "2.  Run the data ingestion  and eda modules to create the top 10 countries data\n",
    "3.  Submit the file using flask as data.txt but in json format\n",
    "4.  ARIMA model will train on the data and report  for each country  MAPE, RMSE\n",
    "5.  The log files will have both train and predict logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"country\": {\n",
      "    \"0\": \"United Kingdom\", \n",
      "    \"1\": \"France\", \n",
      "    \"2\": \"Belgium\", \n",
      "    \"3\": \"EIRE\", \n",
      "    \"4\": \"Germany\", \n",
      "    \"5\": \"Portugal\", \n",
      "    \"6\": \"Netherlands\", \n",
      "    \"7\": \"Spain\", \n",
      "    \"8\": \"Norway\", \n",
      "    \"9\": \"Switzerland\"\n",
      "  }, \n",
      "  \"mape\": {\n",
      "    \"0\": 19, \n",
      "    \"1\": 26, \n",
      "    \"2\": 48, \n",
      "    \"3\": 24, \n",
      "    \"4\": 36, \n",
      "    \"5\": 68, \n",
      "    \"6\": 958, \n",
      "    \"7\": 51, \n",
      "    \"8\": 100, \n",
      "    \"9\": 44\n",
      "  }, \n",
      "  \"rmse\": {\n",
      "    \"0\": 4805.55, \n",
      "    \"1\": 230.66, \n",
      "    \"2\": 156.52, \n",
      "    \"3\": 442.61, \n",
      "    \"4\": 385.81, \n",
      "    \"5\": 2895.75, \n",
      "    \"6\": 358.91, \n",
      "    \"7\": 233.64, \n",
      "    \"8\": 1344.39, \n",
      "    \"9\": 471.57\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port = 8082\n",
    "\n",
    "fileup= open(\"./data/data.txt\",\"rb\")\n",
    "response = requests.post(\"http://0.0.0.0:{}/train\".format(port),files ={\"file\":fileup})\n",
    "print (response.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/logger.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/logger.py\n",
    "\"\"\"\n",
    "module with functions to enable logging\n",
    "\"\"\"\n",
    "\n",
    "import time,os,re,csv,sys,uuid,joblib\n",
    "from datetime import date\n",
    "\n",
    "if not os.path.exists(os.path.join(\".\",\"logs\")):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "def update_train_log(data_shape, eval_test, runtime, MODEL_VERSION, MODEL_VERSION_NOTE, test=False):\n",
    "    \"\"\"\n",
    "    update train log file\n",
    "    \"\"\"\n",
    "\n",
    "    ## name the logfile using something that cycles with date (day, month, year)    \n",
    "    today = date.today()\n",
    "    if test:\n",
    "        logfile = os.path.join(\"logs\", \"train-test.log\")\n",
    "    else:\n",
    "        logfile = os.path.join(\"logs\", \"train-{}-{}.log\".format(today.year, today.month))\n",
    "        \n",
    "    ## write the data to a csv file    \n",
    "    header = ['unique_id','timestamp','x_shape','eval_test','model_version',\n",
    "              'model_version_note','runtime']\n",
    "    write_header = False\n",
    "    if not os.path.exists(logfile):\n",
    "        write_header = True\n",
    "    with open(logfile, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        to_write = map(str, [uuid.uuid4(), time.time(), data_shape, eval_test,\n",
    "                            MODEL_VERSION, MODEL_VERSION_NOTE, runtime])\n",
    "        writer.writerow(to_write)\n",
    "        \n",
    "\n",
    "def update_predict_log(y_pred, y_proba, query, runtime, MODEL_VERSION, test=False):\n",
    "    \"\"\"\n",
    "    update predict log file\n",
    "    \"\"\"\n",
    "\n",
    "    ## name the logfile using something that cycles with date (day, month, year)    \n",
    "    today = date.today()\n",
    "    if test:\n",
    "        logfile = os.path.join(\"logs\", \"predict-test.log\")\n",
    "    else:\n",
    "        logfile = os.path.join(\"logs\", \"predict-{}-{}.log\".format(today.year, today.month))\n",
    "        \n",
    "    ## write the data to a csv file    \n",
    "    header = ['unique_id','timestamp','y_pred','y_proba','query','model_version','runtime']\n",
    "    write_header = False\n",
    "    if not os.path.exists(logfile):\n",
    "        write_header = True\n",
    "    with open(logfile,'a') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        if write_header:\n",
    "            writer.writerow(header)\n",
    "\n",
    "        to_write = map(str,[uuid.uuid4(), time.time(), y_pred, y_proba,query,\n",
    "                            MODEL_VERSION, runtime])\n",
    "        writer.writerow(to_write)\n",
    "\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\"\n",
    "    basic test procedure for logger.py\n",
    "    \"\"\"\n",
    "\n",
    "    from modelapp import MODEL_VERSION, MODEL_VERSION_NOTE\n",
    "    \n",
    "    ## train logger\n",
    "    update_train_log(str((100,10)),\"{'rmse':0.5}\",\"00:00:01\",MODEL_VERSION, MODEL_VERSION_NOTE, test=True)\n",
    "    ## predict logger\n",
    "    update_predict_log(\"[0]\", \"[0.6,0.4]\",\"['united_states', 24, 'aavail_basic', 8]\",\"00:00:01\", MODEL_VERSION, test=True)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\r\n"
     ]
    }
   ],
   "source": [
    "!python3 logger.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/unittests/LoggerTests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/unittests/LoggerTests.py\n",
    "\"\"\"\n",
    "model tests\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "import csv\n",
    "import unittest\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "sys.path.insert(1, os.path.join('..', os.getcwd()))\n",
    "\n",
    "## import model specific functions and variables\n",
    "from logger import update_train_log, update_predict_log\n",
    "\n",
    "\n",
    "\n",
    "class LoggerTest(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    test the essential functionality\n",
    "    \"\"\"\n",
    "        \n",
    "    def test_01_train(self):\n",
    "        \"\"\"\n",
    "        ensure log file is created\n",
    "        \"\"\"\n",
    "\n",
    "        log_file = os.path.join(\"logs\", \"train-test.log\")\n",
    "        if os.path.exists(log_file):\n",
    "            os.remove(log_file)\n",
    "        \n",
    "        ## update the log\n",
    "        data_shape = (100,10)\n",
    "        eval_test = {'rmse':0.5}\n",
    "        runtime = \"00:00:01\"\n",
    "        model_version = 0.1\n",
    "        model_version_note = \"test model\"\n",
    "        \n",
    "        update_train_log(data_shape,eval_test, runtime,model_version, model_version_note, test=True)\n",
    "\n",
    "        self.assertTrue(os.path.exists(log_file))\n",
    "        \n",
    "    def test_02_train(self):\n",
    "        \"\"\"\n",
    "        ensure that content can be retrieved from log file\n",
    "        \"\"\"\n",
    "\n",
    "        log_file = os.path.join(\"logs\", \"train-test.log\")\n",
    "        \n",
    "        ## update the log\n",
    "        data_shape = (100,10)\n",
    "        eval_test = {'rmse':0.5}\n",
    "        runtime = \"00:00:01\"\n",
    "        model_version = 0.1\n",
    "        model_version_note = \"test model\"\n",
    "        \n",
    "        update_train_log(data_shape,eval_test, runtime,model_version, model_version_note, test=True)\n",
    "\n",
    "        df = pd.read_csv(log_file)\n",
    "        logged_eval_test = [literal_eval(i) for i in df['eval_test'].copy()][-1]\n",
    "        self.assertEqual(eval_test, logged_eval_test)\n",
    "                \n",
    "\n",
    "    def test_03_predict(self):\n",
    "        \"\"\"\n",
    "        ensure log file is created\n",
    "        \"\"\"\n",
    "\n",
    "        log_file = os.path.join(\"logs\",\"predict-test.log\")\n",
    "        if os.path.exists(log_file):\n",
    "            os.remove(log_file)\n",
    "        \n",
    "        ## update the log\n",
    "        y_pred = [0]\n",
    "        y_proba = [0.6, 0.4]\n",
    "        runtime = \"00:00:02\"\n",
    "        model_version = 0.1\n",
    "        query = ['united_states', 24, 'aavail_basic', 8]\n",
    "\n",
    "        update_predict_log(y_pred, y_proba, query, runtime,\n",
    "                           model_version, test=True)\n",
    "        \n",
    "        self.assertTrue(os.path.exists(log_file))\n",
    "\n",
    "    \n",
    "    def test_04_predict(self):\n",
    "        \"\"\"\n",
    "        ensure that content can be retrieved from log file\n",
    "        \"\"\"\n",
    "\n",
    "        log_file = os.path.join(\"logs\",\"predict-test.log\")\n",
    "\n",
    "        ## update the log\n",
    "        y_pred = [0]\n",
    "        y_proba = [0.6, 0.4]\n",
    "        runtime = \"00:00:02\"\n",
    "        model_version = 0.1\n",
    "        query = {\"country\":\"United Kindgom\",\"date\":\"01/08/2019\"}\n",
    "\n",
    "        update_predict_log(y_pred, y_proba, query, runtime,\n",
    "                           model_version, test=True)\n",
    "\n",
    "        df = pd.read_csv(log_file)\n",
    "        logged_y_pred = [literal_eval(i) for i in df['y_pred'].copy()][-1]\n",
    "        self.assertEqual(y_pred,logged_y_pred)\n",
    "\n",
    "\n",
    "### Run the tests\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 4 tests in 0.035s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./runtime/unittests/LoggerTests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/unittests/ApiTests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/unittests/ApiTests.py\n",
    "\"\"\"\n",
    "api tests\n",
    "\n",
    "these tests use the requests package however similar requests can be made with curl\n",
    "\n",
    "e.g.\n",
    "\n",
    "data = '{\"key\":\"value\"}'\n",
    "curl -X POST -H \"Content-Type: application/json\" -d \"%s\" http://localhost:8080/predict'%(data)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import unittest\n",
    "import requests\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "port = 8080\n",
    "\n",
    "try:\n",
    "    requests.post('http://0.0.0.0:{}/predict'.format(port))\n",
    "    server_available = True\n",
    "except:\n",
    "    server_available = False\n",
    "    \n",
    "## test class for the main window function\n",
    "class ApiTest(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    test the essential functionality\n",
    "    \"\"\"\n",
    "\n",
    "    @unittest.skipUnless(server_available, \"local server is not running\")\n",
    "    def test_01_train(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "      \n",
    "        request_json = {'mode':'test'}\n",
    "        r = requests.post('http://0.0.0.0:{}/train'.format(port), json=request_json)\n",
    "        train_complete = re.sub(\"\\W+\", \"\", r.text)\n",
    "        self.assertEqual(train_complete, 'true')\n",
    "    \n",
    "    @unittest.skipUnless(server_available, \"local server is not running\")\n",
    "    def test_02_predict_empty(self):\n",
    "        \"\"\"\n",
    "        ensure appropriate failure types\n",
    "        \"\"\"\n",
    "    \n",
    "        ## provide no data at all \n",
    "        r = requests.post('http://0.0.0.0:{}/predict'.format(port))\n",
    "        self.assertEqual(re.sub('\\n|\"', '', r.text), \"[]\")\n",
    "\n",
    "        ## provide improperly formatted data\n",
    "        r = requests.post('http://127.0.0.1:{}/predict'.format(port), json={\"key\":\"value\"})     \n",
    "        self.assertEqual(re.sub('\\n|\"', '', r.text),\"[]\")\n",
    "    \n",
    "    @unittest.skipUnless(server_available,\"local server is not running\")\n",
    "    def test_03_predict(self):\n",
    "        \"\"\"\n",
    "        test the predict functionality\n",
    "        \"\"\"\n",
    "\n",
    "        query_data = {\"country\":\"United Kingdom\", \"date\" :\"01/08/2019\"}\n",
    "\n",
    "        query_type = 'dict'\n",
    "        request_json = {'query':query_data, 'type':query_type}\n",
    "\n",
    "        r = requests.post('http://0.0.0.0:{}/predict'.format(port), json=request_json)\n",
    "        response = literal_eval(r.text)\n",
    "\n",
    "        self.assertTrue(response  =={\"Predrevenue\": 8071.077, \"status\": 200 })\n",
    "\n",
    "    @unittest.skipUnless(server_available, \"local server is not running\")\n",
    "    def test_04_logs(self):\n",
    "        \"\"\"\n",
    "        test the log functionality\n",
    "        \"\"\"\n",
    "\n",
    "        file_name = 'train-test.log'\n",
    "        request_json = {'file':'train-test.log'}\n",
    "        r = requests.get('http://127.0.0.1:{}/logs/{}'.format(port, file_name))\n",
    "\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "        self.assertTrue(os.path.exists(file_name))\n",
    "\n",
    "        if os.path.exists(file_name):\n",
    "            os.remove(file_name)\n",
    "\n",
    "        \n",
    "### Run the tests\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./runtime/unittests/ApiTests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/unittests/ApiTests.py\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "model tests\n",
    "\"\"\"\n",
    "\n",
    "import sys, os\n",
    "import unittest\n",
    "sys.path.insert(1, os.path.join('..', os.getcwd()))\n",
    "\n",
    "## import model specific functions and variables\n",
    "from model import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ModelTest(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    test the essential functionality\n",
    "    \"\"\"\n",
    "        \n",
    "    def test_01_train(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "\n",
    "        ## train the model\n",
    "        model_train(test=True)\n",
    "        self.assertTrue(os.path.exists(os.path.join(\"models\", \"test.joblib\")))\n",
    "\n",
    "    def test_02_load(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "                        \n",
    "        ## train the model\n",
    "        model = model_load(test=True)\n",
    "        \n",
    "        self.assertTrue('predict' in dir(model))\n",
    "        self.assertTrue('fit' in dir(model))\n",
    "\n",
    "          \n",
    "### Run the tests\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./runtime/run_all_tests\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./runtime/run_all_tests\n",
    "\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "from unittests import *\n",
    "unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
