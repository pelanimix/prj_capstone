{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test-example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  test-example.py\n",
    "\n",
    "import unittest\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# function or class to be tested\n",
    "def slr_predict(x_query):\n",
    "    \"\"\"\n",
    "    given a simple linear regression make a prediction for x\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(x_query, float):\n",
    "        x_query = np.array([x_query])\n",
    "    elif isinstance(x_query, str):\n",
    "        if not re.search(\"\\d+\",x_query):\n",
    "            raise Exception(\"non-numeric string input provided\")\n",
    "        x_query = np.array([float(x_query)])\n",
    "    elif isinstance(x_query, list):\n",
    "        x_query = np.array(x_query)\n",
    "        \n",
    "    ## generate data for linear regression\n",
    "    x = np.array([0, 1, 2, 3, 4])\n",
    "    y = np.array([-1, 0.15, 0.95, 2.1, 2.8])\n",
    "    \n",
    "    ## estimate the coeffs using lstsq\n",
    "    A = np.vstack([x, np.ones(len(x))]).T\n",
    "    coeffs = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "\n",
    "    return(coeffs[0] + (coeffs[1] * x_query))\n",
    "    \n",
    "class TestSimpleLinearRegressionPredict(unittest.TestCase):\n",
    "\n",
    "    # example test method\n",
    "    def test_numeric(self):\n",
    "        y_pred = slr_predict(0.5)\n",
    "        self.assertEqual(0.5, y_pred[0])\n",
    "\n",
    "    def test_str(self):\n",
    "        y_pred = slr_predict('0.5')\n",
    "        self.assertEqual(0.5, y_pred[0])\n",
    "\n",
    "    def test_list(self):\n",
    "        y_pred = slr_predict([0.5, 0.1])\n",
    "        self.assertEqual(0.5, y_pred[0])\n",
    "    \n",
    "    def test_array(self):\n",
    "        y_pred = slr_predict(np.array([0.5, 0.1]))\n",
    "        self.assertEqual(0.5, y_pred[0])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFFF\r\n",
      "======================================================================\r\n",
      "FAIL: test_array (test-example.TestSimpleLinearRegressionPredict)\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/pelani/development/python/revision/docker-tutorial/test-example.py\", line 49, in test_array\r\n",
      "    self.assertEqual(0.5, y_pred[0])\r\n",
      "AssertionError: 0.5 != 0.4999999999999998\r\n",
      "\r\n",
      "======================================================================\r\n",
      "FAIL: test_list (test-example.TestSimpleLinearRegressionPredict)\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/pelani/development/python/revision/docker-tutorial/test-example.py\", line 45, in test_list\r\n",
      "    self.assertEqual(0.5, y_pred[0])\r\n",
      "AssertionError: 0.5 != 0.4999999999999998\r\n",
      "\r\n",
      "======================================================================\r\n",
      "FAIL: test_numeric (test-example.TestSimpleLinearRegressionPredict)\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/pelani/development/python/revision/docker-tutorial/test-example.py\", line 37, in test_numeric\r\n",
      "    self.assertEqual(0.5, y_pred[0])\r\n",
      "AssertionError: 0.5 != 0.4999999999999998\r\n",
      "\r\n",
      "======================================================================\r\n",
      "FAIL: test_str (test-example.TestSimpleLinearRegressionPredict)\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/pelani/development/python/revision/docker-tutorial/test-example.py\", line 41, in test_str\r\n",
      "    self.assertEqual(0.5, y_pred[0])\r\n",
      "AssertionError: 0.5 != 0.4999999999999998\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 4 tests in 0.003s\r\n",
      "\r\n",
      "FAILED (failures=4)\r\n"
     ]
    }
   ],
   "source": [
    "import!python3 -m unittest test-example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6604bd113feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_ts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nMissing Value Summary\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6604bd113feb>\u001b[0m in \u001b[0;36mfetch_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'./data/data.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconvert_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"invoice_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#df = pd.read_json(os.path.join(DATA_DIR,\"data.txt\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df size : {} x {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Invalid file path or buffer object type: {type(filepath_or_buffer)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'dict'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "DATA_DIR = os.path.join(\".\",\"data\")\n",
    "MODEL_VERSION = \"0.1\"\n",
    "MODEL_VERSION_NOTE = \"auto_arima\"\n",
    "\n",
    "\n",
    "def fetch_data():\n",
    "    #df = pd.read_csv(os.path.join(DATA_DIR, \"top10countries-data.csv\"),index_col=0, parse_dates=['invoice_date'])\n",
    "    f = open ('./data/data.txt',\"r\")\n",
    "    dt = json.loads(f.read())\n",
    "    df = pd.read_json(dt,orient='split',convert_dates=[\"invoice_date\"])\n",
    "    #df = pd.read_json(os.path.join(DATA_DIR,\"data.txt\"))\n",
    "    print(\"df size : {} x {}\".format(df.shape[0], df.shape[1]))\n",
    "\n",
    "    ## check the first few rows\n",
    "    print(\"\\n  Check first 4 rows\\n\")\n",
    "    print(df.head(n=4))\n",
    "    print(df.groupby(df.index))\n",
    "    \n",
    "    return df \n",
    "def filter_cntry_data(df,country):\n",
    "    df = df[df.index==country]\n",
    "    ts = df.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"sales\")\n",
    "    \n",
    "    y_ts = ts.resample('MS').mean()\n",
    "    \n",
    "    return y_ts\n",
    "\n",
    "data = fetch_data()\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(data.isnull().sum(axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2017-11-01', '2017-12-01', '2018-01-01', '2018-02-01',\n",
      "               '2018-03-01', '2018-04-01', '2018-05-01', '2018-06-01',\n",
      "               '2018-07-01', '2018-08-01', '2018-09-01', '2018-10-01',\n",
      "               '2018-11-01', '2018-12-01', '2019-01-01', '2019-02-01',\n",
      "               '2019-03-01', '2019-04-01', '2019-05-01', '2019-06-01',\n",
      "               '2019-07-01'],\n",
      "              dtype='datetime64[ns]', name='invoice_date', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "ts = data.groupby(\"invoice_date\")[\"revenue\"].sum().rename(\"Sales\")\n",
    "#data does not have daily sales so for the model, it will be analysed based on  monthly averages\n",
    "\n",
    "\n",
    "y = round(ts.resample('MS').mean(),2)\n",
    "\n",
    "print(y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_res = pd.DataFrame(columns=[\"country\",\"rmse\",\"mape\"])\n",
    "\n",
    "country  = data.index.unique().tolist()\n",
    "\n",
    "c_listlen= len(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_listlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United Kingdom',\n",
       " 'France',\n",
       " 'Belgium',\n",
       " 'EIRE',\n",
       " 'Germany',\n",
       " 'Portugal',\n",
       " 'Netherlands',\n",
       " 'Spain',\n",
       " 'Norway',\n",
       " 'Switzerland']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "united kingdom\n",
      "..saving model united kingdom-sales-arima-0_1.joblib\n",
      "france\n",
      "..saving model france-sales-arima-0_1.joblib\n",
      "belgium\n",
      "..saving model belgium-sales-arima-0_1.joblib\n",
      "eire\n",
      "..saving model eire-sales-arima-0_1.joblib\n",
      "germany\n",
      "..saving model germany-sales-arima-0_1.joblib\n",
      "portugal\n",
      "..saving model portugal-sales-arima-0_1.joblib\n",
      "netherlands\n",
      "..saving model netherlands-sales-arima-0_1.joblib\n",
      "spain\n",
      "..saving model spain-sales-arima-0_1.joblib\n",
      "norway\n",
      "..saving model norway-sales-arima-0_1.joblib\n",
      "switzerland\n",
      "..saving model switzerland-sales-arima-0_1.joblib\n",
      "{'country': {0: 'United Kingdom', 1: 'France', 2: 'Belgium', 3: 'EIRE', 4: 'Germany', 5: 'Portugal', 6: 'Netherlands', 7: 'Spain', 8: 'Norway', 9: 'Switzerland'}, 'rmse': {0: 4, 1: 4, 2: 4, 3: 4, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, 9: 4}, 'mape': {0: 5, 1: 5, 2: 5, 3: 5, 4: 5, 5: 5, 6: 5, 7: 5, 8: 5, 9: 5}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(c_listlen):\n",
    "        cntry = country[i]\n",
    "        #format the country variable\n",
    "        if cntry.isspace():\n",
    "            str_country= cntry\n",
    "            str_country = re.sub(r\"\\s+\",'-',str_country)\n",
    "            str_country =str_country.lower()\n",
    "            print(\"has space \" +str_country)\n",
    "        else:\n",
    "            str_country = cntry.lower()\n",
    "            print(str_country)\n",
    "        #set country model\n",
    "        saved_model = str_country+\"-\"+\"sales-arima-{}.joblib\".format(re.sub(\"\\.\", \"_\", str(MODEL_VERSION)))\n",
    "        print(\"..saving model \"+ saved_model)\n",
    "        #filter data to train based on country \n",
    "        y =filter_cntry_data(data,cntry)\n",
    "        \n",
    "        #print(\"\\n top 4 for country \"+cntry +\"\\n\")\n",
    "        #print(y.head(n=4))\n",
    "        df_res.loc[i] = [cntry,4,5] \n",
    "        \n",
    "print(df_res.to_dict())\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
